import os
import numpy as np
import cv2
from os.path import join
import glob
import matplotlib.pyplot as plt
import skimage
import time
import math
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
from tqdm import tqdm

train_img_paths = glob.glob('./train/train_ref/*.BMP')
test_img_paths  = glob.glob('./test1/test/*.BMP')  

# 원본 이미지 로드
img_train_list = []
for path in tqdm(train_img_paths, desc="Loading Train Images"):
    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    img_train_list.append(img)

img_test_list = []
for path in tqdm(test_img_paths, desc="Loading Test Images"):
    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    img_test_list.append(img)

print(f"Loaded {len(img_train_list)} train images, {len(img_test_list)} test images.")

# ORB + BFMatcher 초기화

orb = cv2.ORB_create(1000)
bf  = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)

def match_pair_orb(img1, img2, min_matches=8):
    kp1, des1 = orb.detectAndCompute(img1, None)
    kp2, des2 = orb.detectAndCompute(img2, None)
    # (1) 항상 5개 리턴
    if des1 is None or des2 is None:
        return None, None, None, None, 0

    matches = bf.match(des1, des2)
    if len(matches) < min_matches:
        return None, None, None, None, 0

    matches = sorted(matches, key=lambda m: m.distance)[: min_matches*3]
    pts1 = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1,2)
    pts2 = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1,2)
    if len(pts1) < 3:
        return None, None, None, None, 0

    M, mask = cv2.estimateAffinePartial2D(
        pts1, pts2,
        method=cv2.RANSAC,
        ransacReprojThreshold=5.0,
        maxIters=2000
    )
    if M is None or mask is None:
        return None, None, None, None, 0

    score = int(mask.sum())
    return M, mask, pts1, pts2, score

# 전체 매칭 & mask/pts 저장

results = []
for i, img_t in enumerate(tqdm(img_test_list, desc="Matching Test→Train")):
    best = {
        'score': 0,
        'train_idx': None,
        'M': None,
        'mask': None,
        'pts1': None,
        'pts2': None
    }
    for j, img_g in enumerate(img_train_list):
        M, mask, pts1, pts2, score = match_pair_orb(img_t, img_g)
        if score > best['score']:
            best.update(
                score=score,
                train_idx=j,    # ← j로 수정
                M=M, mask=mask,
                pts1=pts1, pts2=pts2
            )
    results.append(best)

def display_match(test_idx):
    # 1) 매칭 결과 꺼내기
    r      = results[test_idx]
    M, mask, pts1, pts2 = r['M'], r['mask'], r['pts1'], r['pts2']
    gi     = r['train_idx']
    score  = r['score']                # inlier 개수
    total  = pts1.shape[0]             # 매칭 시도한 전체 키포인트 개수
    sim    = (score / total * 100) if total>0 else 0  # 유사도 %

    # 2) 원본 그레이스케일 불러오기
    img_t  = img_test_list[test_idx]
    img_g  = img_train_list[gi]
    h, w   = img_t.shape

    # 3) 컬러 캔버스 준비
    canvas = np.zeros((h, w*2, 3), dtype=np.uint8)
    canvas[:, :w]   = cv2.cvtColor(img_t, cv2.COLOR_GRAY2BGR)
    canvas[:, w:]   = cv2.cvtColor(img_g, cv2.COLOR_GRAY2BGR)

    # 4) inlier 포인트만 골라 warp
    in1    = pts1[mask.ravel()==1]
    in2    = pts2[mask.ravel()==1]
    in1_tr = cv2.transform(in1.reshape(-1,1,2), M).reshape(-1,2)

    # 5) 노란색 선 그리기
    for (x1,y1),(x2,y2) in zip(in1_tr, in2):
        cv2.line(canvas,
                 (int(x1),    int(y1)),
                 (int(x2)+w,  int(y2)),
                 color=(0,255,255), thickness=1)

    # 6) 파일명 & 유사도 텍스트
    test_name  = os.path.basename(test_img_paths[test_idx])
    train_name = os.path.basename(train_img_paths[ gi ])
    title_str  = f"test: {test_name} ↔ train: {train_name}   Inliers: {score}, Similarity: {sim:.1f}%"

    # 7) 화면에 보여주기 (matplotlib는 RGB)
    plt.figure(figsize=(12,6))
    plt.imshow(cv2.cvtColor(canvas, cv2.COLOR_BGR2RGB))
    plt.title(title_str)
    plt.axis('off')
    plt.show()

# 사용 예
idx = next(i for i,p in enumerate(test_img_paths)
           if os.path.basename(p)=='1.BMP')
display_match(idx)
def decompose_affine(M):
    """
    M: 2x3 Affine 변환 행렬 (cv2.estimateAffinePartial2D 결과)
    반환: theta (degree), translation(x,y)
    """
    if M is None:
        return None, None

    # 회전 행렬 부분
    a, b = M[0,0], M[0,1]
    c, d = M[1,0], M[1,1]

    # 회전 각도 (rad → degree)
    theta_rad = np.arctan2(c, a)
    theta_deg = np.degrees(theta_rad)

    # 이동 벡터
    tx, ty = M[0,2], M[1,2]

    return theta_deg, (tx, ty)
idx = next(i for i,p in enumerate(test_img_paths)
           if os.path.basename(p)=='1.BMP')
r = results[idx]
M = r['M']

theta_deg, (tx, ty) = decompose_affine(M)
print(f"[Pose 추정]")
print(f"  회전각 (deg): {theta_deg:.2f}")
print(f"affine 행렬:")
print(M)
print(f"  이동벡터   : ({tx:.2f}, {ty:.2f})")
